{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3047725,"sourceType":"datasetVersion","datasetId":1866301}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# imports\nimport torch\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-20T19:04:07.127528Z","iopub.execute_input":"2024-09-20T19:04:07.128037Z","iopub.status.idle":"2024-09-20T19:04:07.135668Z","shell.execute_reply.started":"2024-09-20T19:04:07.127989Z","shell.execute_reply":"2024-09-20T19:04:07.134210Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"# load dataset\ndf = pd.read_csv('/kaggle/input/wine-quality-dataset/WineQT.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2024-09-20T19:04:07.138034Z","iopub.execute_input":"2024-09-20T19:04:07.138496Z","iopub.status.idle":"2024-09-20T19:04:07.187770Z","shell.execute_reply.started":"2024-09-20T19:04:07.138452Z","shell.execute_reply":"2024-09-20T19:04:07.186145Z"},"trusted":true},"execution_count":107,"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0               7.4             0.700         0.00             1.9      0.076   \n1               7.8             0.880         0.00             2.6      0.098   \n2               7.8             0.760         0.04             2.3      0.092   \n3              11.2             0.280         0.56             1.9      0.075   \n4               7.4             0.700         0.00             1.9      0.076   \n...             ...               ...          ...             ...        ...   \n1138            6.3             0.510         0.13             2.3      0.076   \n1139            6.8             0.620         0.08             1.9      0.068   \n1140            6.2             0.600         0.08             2.0      0.090   \n1141            5.9             0.550         0.10             2.2      0.062   \n1142            5.9             0.645         0.12             2.0      0.075   \n\n      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                    11.0                  34.0  0.99780  3.51       0.56   \n1                    25.0                  67.0  0.99680  3.20       0.68   \n2                    15.0                  54.0  0.99700  3.26       0.65   \n3                    17.0                  60.0  0.99800  3.16       0.58   \n4                    11.0                  34.0  0.99780  3.51       0.56   \n...                   ...                   ...      ...   ...        ...   \n1138                 29.0                  40.0  0.99574  3.42       0.75   \n1139                 28.0                  38.0  0.99651  3.42       0.82   \n1140                 32.0                  44.0  0.99490  3.45       0.58   \n1141                 39.0                  51.0  0.99512  3.52       0.76   \n1142                 32.0                  44.0  0.99547  3.57       0.71   \n\n      alcohol  quality    Id  \n0         9.4        5     0  \n1         9.8        5     1  \n2         9.8        5     2  \n3         9.8        6     3  \n4         9.4        5     4  \n...       ...      ...   ...  \n1138     11.0        6  1592  \n1139      9.5        6  1593  \n1140     10.5        5  1594  \n1141     11.2        6  1595  \n1142     10.2        5  1597  \n\n[1143 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n      <th>Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.880</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.99680</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.760</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.99700</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.280</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.99800</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1138</th>\n      <td>6.3</td>\n      <td>0.510</td>\n      <td>0.13</td>\n      <td>2.3</td>\n      <td>0.076</td>\n      <td>29.0</td>\n      <td>40.0</td>\n      <td>0.99574</td>\n      <td>3.42</td>\n      <td>0.75</td>\n      <td>11.0</td>\n      <td>6</td>\n      <td>1592</td>\n    </tr>\n    <tr>\n      <th>1139</th>\n      <td>6.8</td>\n      <td>0.620</td>\n      <td>0.08</td>\n      <td>1.9</td>\n      <td>0.068</td>\n      <td>28.0</td>\n      <td>38.0</td>\n      <td>0.99651</td>\n      <td>3.42</td>\n      <td>0.82</td>\n      <td>9.5</td>\n      <td>6</td>\n      <td>1593</td>\n    </tr>\n    <tr>\n      <th>1140</th>\n      <td>6.2</td>\n      <td>0.600</td>\n      <td>0.08</td>\n      <td>2.0</td>\n      <td>0.090</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99490</td>\n      <td>3.45</td>\n      <td>0.58</td>\n      <td>10.5</td>\n      <td>5</td>\n      <td>1594</td>\n    </tr>\n    <tr>\n      <th>1141</th>\n      <td>5.9</td>\n      <td>0.550</td>\n      <td>0.10</td>\n      <td>2.2</td>\n      <td>0.062</td>\n      <td>39.0</td>\n      <td>51.0</td>\n      <td>0.99512</td>\n      <td>3.52</td>\n      <td>0.76</td>\n      <td>11.2</td>\n      <td>6</td>\n      <td>1595</td>\n    </tr>\n    <tr>\n      <th>1142</th>\n      <td>5.9</td>\n      <td>0.645</td>\n      <td>0.12</td>\n      <td>2.0</td>\n      <td>0.075</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99547</td>\n      <td>3.57</td>\n      <td>0.71</td>\n      <td>10.2</td>\n      <td>5</td>\n      <td>1597</td>\n    </tr>\n  </tbody>\n</table>\n<p>1143 rows Ã— 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# preprocess dataset\ndf = df.drop(['Id'], axis=1)\n\nX = df.drop(['quality'], axis=1).values\ny = df['quality'].values\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X, y)\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T19:04:07.189753Z","iopub.execute_input":"2024-09-20T19:04:07.190280Z","iopub.status.idle":"2024-09-20T19:04:07.202788Z","shell.execute_reply.started":"2024-09-20T19:04:07.190234Z","shell.execute_reply":"2024-09-20T19:04:07.201282Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"class WineNeuralNetwork(nn.Module):\n    def __init__(self, input_size):\n        super(WineNeuralNetwork, self).__init__()\n        self.layer1 = nn.Linear(input_size, 64)\n        self.layer2 = nn.Linear(64, 64)\n        self.layer3 = nn.Linear(64, 1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.sigmoid(self.layer1(x))\n        x = self.sigmoid(self.layer2(x))\n        x = self.layer3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-20T19:04:07.206184Z","iopub.execute_input":"2024-09-20T19:04:07.206684Z","iopub.status.idle":"2024-09-20T19:04:07.220593Z","shell.execute_reply.started":"2024-09-20T19:04:07.206639Z","shell.execute_reply":"2024-09-20T19:04:07.219139Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# create dataset class\nclass WineDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T19:04:07.222211Z","iopub.execute_input":"2024-09-20T19:04:07.222786Z","iopub.status.idle":"2024-09-20T19:04:07.243227Z","shell.execute_reply.started":"2024-09-20T19:04:07.222724Z","shell.execute_reply":"2024-09-20T19:04:07.241380Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# training function\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n    for epoch in range(num_epochs):\n        model.train()\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        \n        # Validation\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                outputs = model(inputs)\n                val_loss += criterion(outputs, labels).item()\n        \n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss/len(val_loader):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-20T19:04:07.245233Z","iopub.execute_input":"2024-09-20T19:04:07.245812Z","iopub.status.idle":"2024-09-20T19:04:07.263537Z","shell.execute_reply.started":"2024-09-20T19:04:07.245756Z","shell.execute_reply":"2024-09-20T19:04:07.261666Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"# create the model\ntrain_dataset = WineDataset(X_train, y_train)\ntest_dataset = WineDataset(X_test, y_test)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\ninput_size = X_train.shape[1]\nmodel = WineNeuralNetwork(input_size)\ncriterion = nn.MSELoss()\noptimizer= optim.AdamW(model.parameters(), lr=0.001)\n\ntrain_model(model, train_loader, test_loader, criterion, optimizer, 40)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T19:04:07.266053Z","iopub.execute_input":"2024-09-20T19:04:07.266726Z","iopub.status.idle":"2024-09-20T19:04:10.025079Z","shell.execute_reply.started":"2024-09-20T19:04:07.266672Z","shell.execute_reply":"2024-09-20T19:04:10.023865Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Epoch [1/40], Loss: 17.9353, Val Loss: 15.6427\nEpoch [2/40], Loss: 4.8880, Val Loss: 6.1990\nEpoch [3/40], Loss: 2.9637, Val Loss: 2.1637\nEpoch [4/40], Loss: 1.1587, Val Loss: 0.8460\nEpoch [5/40], Loss: 0.3420, Val Loss: 0.5807\nEpoch [6/40], Loss: 0.7326, Val Loss: 0.5307\nEpoch [7/40], Loss: 0.4901, Val Loss: 0.5142\nEpoch [8/40], Loss: 0.1812, Val Loss: 0.4986\nEpoch [9/40], Loss: 0.4680, Val Loss: 0.4851\nEpoch [10/40], Loss: 0.4729, Val Loss: 0.4725\nEpoch [11/40], Loss: 0.6865, Val Loss: 0.4614\nEpoch [12/40], Loss: 0.4503, Val Loss: 0.4507\nEpoch [13/40], Loss: 0.3632, Val Loss: 0.4419\nEpoch [14/40], Loss: 0.3442, Val Loss: 0.4342\nEpoch [15/40], Loss: 0.5753, Val Loss: 0.4287\nEpoch [16/40], Loss: 0.4868, Val Loss: 0.4242\nEpoch [17/40], Loss: 0.5427, Val Loss: 0.4202\nEpoch [18/40], Loss: 0.5022, Val Loss: 0.4167\nEpoch [19/40], Loss: 0.4428, Val Loss: 0.4138\nEpoch [20/40], Loss: 0.2983, Val Loss: 0.4115\nEpoch [21/40], Loss: 0.3308, Val Loss: 0.4097\nEpoch [22/40], Loss: 0.4957, Val Loss: 0.4078\nEpoch [23/40], Loss: 0.5139, Val Loss: 0.4070\nEpoch [24/40], Loss: 0.2451, Val Loss: 0.4052\nEpoch [25/40], Loss: 0.5485, Val Loss: 0.4040\nEpoch [26/40], Loss: 0.5105, Val Loss: 0.4025\nEpoch [27/40], Loss: 0.3427, Val Loss: 0.4023\nEpoch [28/40], Loss: 0.5892, Val Loss: 0.4004\nEpoch [29/40], Loss: 0.6609, Val Loss: 0.3992\nEpoch [30/40], Loss: 0.4335, Val Loss: 0.3983\nEpoch [31/40], Loss: 0.4822, Val Loss: 0.3970\nEpoch [32/40], Loss: 0.4063, Val Loss: 0.3977\nEpoch [33/40], Loss: 0.3638, Val Loss: 0.3952\nEpoch [34/40], Loss: 0.3671, Val Loss: 0.3941\nEpoch [35/40], Loss: 0.1683, Val Loss: 0.3939\nEpoch [36/40], Loss: 0.3234, Val Loss: 0.3920\nEpoch [37/40], Loss: 0.3569, Val Loss: 0.3918\nEpoch [38/40], Loss: 0.4692, Val Loss: 0.3920\nEpoch [39/40], Loss: 0.3492, Val Loss: 0.3895\nEpoch [40/40], Loss: 0.6182, Val Loss: 0.3892\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model\nmodel.eval()\ntest_loss = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        outputs = model(inputs)\n        test_loss += criterion(outputs, labels).item()\n\nprint(f'Test Loss: {test_loss/len(test_loader):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-20T19:04:10.026992Z","iopub.execute_input":"2024-09-20T19:04:10.028031Z","iopub.status.idle":"2024-09-20T19:04:10.043639Z","shell.execute_reply.started":"2024-09-20T19:04:10.027969Z","shell.execute_reply":"2024-09-20T19:04:10.042298Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"Test Loss: 0.3892\n","output_type":"stream"}]}]}